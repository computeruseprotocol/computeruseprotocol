# The missing infrastructure layer for cross-platform UI trees

**No universal standard for representing UI accessibility trees across platforms exists today — but the AI agent boom has made building one urgent.** Every major platform (Windows UIA, macOS AXUIElement, Linux AT-SPI2, Web ARIA, Android AccessibilityNodeInfo, iOS UIAccessibility) exposes a structurally similar tree of elements with roles, names, states, bounds, and parent-child relationships — yet each uses incompatible naming, role taxonomies, action models, and IPC mechanisms. The closest realized implementation of a universal schema is **AccessKit**, a Rust library with ~150 ARIA-derived roles and adapters for four platforms, but it solves the inverse problem: helping toolkit authors *provide* trees, not helping agents *consume* them. The emergence of computer-use AI agents — all independently reinventing UI perception — has created a narrow window for an open standard before proprietary solutions lock in.

## Six platforms, one conceptual model, zero interoperability

The fundamental tree shape is remarkably consistent across all six platforms. Every one exposes a hierarchy of nodes, each carrying a semantic type (role), human-readable label (name), boolean state flags, a bounding rectangle, and a set of supported actions. The divergence is in the details:

| Dimension | Windows UIA | macOS AX | Linux AT-SPI2 | Web ARIA | Android | iOS |
|-----------|------------|----------|---------------|----------|---------|-----|
| **Roles** | ~40 ControlTypes | AXRole + AXSubrole | ~100+ AtspiRole values | ~80 ARIA roles | Java class names | ~15 trait flags |
| **Name** | `Name` property | `AXTitle` + `AXDescription` | `accessible-name` | `aria-label` / computed | `contentDescription` | `accessibilityLabel` |
| **Actions** | Control Patterns (Invoke, Toggle, Value) | Named actions (AXPress, AXIncrement) | Action interface methods | DOM events | ACTION_CLICK constants | UIAccessibility methods |
| **IPC** | COM | XPC / Mach ports | D-Bus | In-process | Binder | In-process |
| **Bounds** | `BoundingRectangle` | `AXPosition` + `AXSize` | Component interface | `getBoundingClientRect()` | `getBoundsInScreen()` | `accessibilityFrame` |

**ARIA's role taxonomy has quietly become the de facto lingua franca.** Chromium's internal cross-platform accessibility tree uses roles "that tend to match those defined in the ARIA specification." AccessKit's schema is "largely taken from the ARIA specification." The W3C's Core Accessibility API Mappings spec (Core AAM) uses ARIA as the source taxonomy for mapping to all five platform APIs it covers — UIA, MSAA+IAccessible2, ATK/AT-SPI, macOS AX, and (recently added) Android. Any future universal standard would almost certainly build on ARIA roles.

The **W3C Core AAM** is the closest thing to a formal Rosetta Stone. For every ARIA role, it specifies the corresponding construct on each platform — for instance, `role="button"` maps to UIA `Button` ControlType, ATK `ROLE_PUSH_BUTTON`, macOS `AXButton`, and Android `android.widget.Button`. But Core AAM is a mapping specification for browser implementers, not a standalone universal schema or wire protocol. iOS is covered only implicitly through macOS AX similarity. And the **Accessibility Object Model (AOM)**, which would expose computed accessibility trees programmatically in browsers, remains stuck in WICG incubation after years of work — the W3C working group has acknowledged fundamental disagreements about what a canonical browser accessibility tree even looks like.

## What already exists: a landscape of near-misses

**AccessKit** (github.com/AccessKit/accesskit, ~1.4k stars) represents the most architecturally significant attempt. Derived from Chromium's internal cross-platform abstraction, it defines a unified data schema with ~150 roles, extensive optional properties (name, description, value, bounds, transform, text selection, table coordinates, live region semantics), **22 action types**, and a push-based tree update model. Platform adapters translate this schema into Windows UIA, macOS NSAccessibility, Linux AT-SPI2, and Android accessibility APIs. It has C and Python bindings, and is used by Rust GUI toolkits (egui, Slint, Iced) and the Bevy game engine. However, AccessKit is designed for toolkit authors to *expose* their custom-rendered UIs to assistive technology — not for automation scripts to *read* arbitrary application trees.

**Appium** (github.com/appium/appium, ~19k stars) is the closest production tool to cross-platform UI tree access, covering Android, iOS, macOS, Windows, and Web through its WebDriver-based architecture. Its `getPageSource()` returns the full UI hierarchy as XML. But critically, **Appium does not define a unified schema** — Android returns XML with Java class names and properties like `content-desc` and `bounds`, while iOS returns completely different XML with `XCUIElementType` tags and `label`/`name` attributes. An official `@appium/universal-xml-plugin` attempts to normalize iOS and Android page sources, but it has only ~113 weekly npm downloads and covers just two platforms.

**LDTP** (Linux Desktop Testing Project) was historically the closest to a true "unified cross-platform accessibility API," exposing a common Python/Java/Ruby API across Linux (AT-SPI), Windows (MSAA/UIA via "Cobra"), and macOS (via ATOMac). It proved the concept was viable. But the project is **effectively abandoned** — Windows and macOS support is unreliable with modern operating systems.

In the MCP server ecosystem, **computer-mcp** (CommandAGI) is the most relevant find. This Python MCP server exposes a **unified JSON accessibility tree** across Windows (pywin32/UIA), macOS (pyobjc), and Linux (PyGObject/AT-SPI), with a consistent format: `{"name": "...", "control_type": "...", "bounds": {"x": 0, "y": 0, "width": 1920, "height": 1080}, "children": [...]}`. Other MCP servers are platform-specific: **Playwright MCP** (Microsoft) for web, **mobile-mcp** (MobileNext) for iOS/Android, **Smooth Operator** for Windows UIA, and **AutoMac MCP** for macOS. None bridges all platforms.

The developer experience today is fragmented by necessity. A Python developer wanting to read UI trees across desktop platforms must use **pywinauto** (Windows, ~5.6k stars), **atomacos** (macOS), and **dogtail** or **pyatspi** (Linux) — three separate libraries with incompatible APIs, then write a custom wrapper to normalize the output. For mobile, they add Appium with its server infrastructure overhead. For web, Playwright or Selenium via CDP. **No single `pip install` gives you a unified tree.**

## How AI agents perceive UIs: fragmented but converging

The computer-use agent ecosystem of 2024–2025 reveals three distinct approaches to UI perception, with a clear trend toward hybridization:

**Pure vision agents** like Anthropic's Computer Use rely entirely on screenshots. Claude was trained to "count pixels" from screen edges to determine click coordinates, operating at XGA resolution (1024×768) with no accessibility tree data whatsoever. Microsoft's **OmniParser** (V2, January 2025) takes a complementary approach — a two-model pipeline using fine-tuned YOLOv8 for icon detection and Florence-2 for captioning, converting screenshots into structured element data with bounding boxes. **ShowUI** achieves 75.1% accuracy in zero-shot screenshot grounding with a 2B-parameter model. The appeal is platform-agnosticism: screenshots work identically whether the source is Windows, macOS, a remote desktop, or a game.

**Accessibility-tree-first agents** represent the opposing camp. **Agent-E** (Emergence AI) explicitly chose the DOM Accessibility Tree over raw HTML DOM because "the accessibility tree by nature is geared towards helping screen readers, which is closer to the mission of web automation." **Vercel's agent-browser** returns a compact accessibility tree with stable element references (`@e1`, `@e2`), achieving **93% context reduction** versus Playwright MCP's full tree. Multiple academic frameworks (BrowserAgent, early WebArena) parse Playwright's accessibility tree as their sole observation format.

**Hybrid agents** are becoming dominant. OpenAI's CUA/Operator combines screenshot analysis with **Chrome DevTools Protocol** to extract element bounds and ARIA labels, drawing bounding boxes on screenshots for the vision model. Microsoft's **UFO²** (github.com/microsoft/UFO) is the most sophisticated hybrid — it queries Windows UIA for structured accessibility data as the primary source, falls back to OmniParser vision-based detection for legacy apps that bypass UIA, and fuses both into a "unified control graph." Google's Gemini Computer Use observes both "visual elements and underlying code structures."

The performance gap validates the accessibility tree approach: **agents using structured accessibility data achieve ~85% task completion versus ~50% for vision-only** on standard benchmarks. Playwright MCP reduces token consumption by approximately **90%** compared to raw DOM. Yet the OSWorld benchmark shows even the best agents (OpenAI CUA at 38.1%) far underperform humans (72.4%), suggesting neither approach alone suffices.

**No common format has emerged.** Every project defines its own UI element schema. browser-use has a custom `buildDomTree.js` that produces an indexed selector map. Agent-E distills Playwright's accessibility tree into task-specific views. UFO² serializes UIA control properties differently than computer-mcp's JSON format. The only convergence is conceptual: nearly all systems assign integer or string identifiers to elements, capture role/name/bounds/state, and flag interactability. **Playwright's accessibility tree snapshot is the closest thing to a shared standard**, but only for web agents.

## The case for a protocol — and the LSP playbook

The strongest precedent for this kind of standardization is **Language Server Protocol (LSP)**. Before LSP, every IDE had to implement language support for every programming language — an M×N problem identical to the current situation where every AI agent reimplements accessibility tree access for every platform. LSP solved this by defining a JSON-RPC protocol at "the level of the editor rather than the level of the programming language model" — cursor positions and URIs rather than ASTs. A key design choice was **capability negotiation**: servers announce which features they support, elegantly avoiding the lowest-common-denominator problem. LSP went from VS Code internal project to industry standard in roughly four years.

A UI accessibility tree protocol could follow the same pattern. The core schema would capture the universally shared concepts — **element ID, role (ARIA-based), name, bounding box, state flags, children, and supported actions** — while capability negotiation would let platform adapters expose richer platform-specific data (Windows UIA control patterns, macOS AX subroles, Android resource IDs) as optional extensions. The wire format would likely be JSON over the existing **MCP transport**, immediately plugging into the Claude, Copilot, Cursor, and broader AI agent ecosystem.

**WebDriver's standardization journey is equally instructive.** Selenium created a de facto protocol, grew organically to massive adoption, and only then did W3C formalize it (2018) with browser vendor participation. The lesson: **standardization follows adoption, not the reverse.** A library that gains real users creates the gravitational pull for formalization.

The combined addressable market is substantial. **Test automation** ($20.6B in 2025, 16.8% CAGR), **RPA** ($28.3B, ~30% CAGR), and **AI agents** ($7.6B, 44% CAGR) all suffer from platform fragmentation. RPA vendors like UiPath built proprietary abstraction layers rather than open standards — creating massive vendor lock-in that an open protocol could disrupt. The European Accessibility Act (effective June 2025) adds regulatory pressure for better cross-platform accessibility tooling.

## Real barriers that could kill adoption

**Apple is the critical bottleneck.** Microsoft would likely support standardization (they created LSP, open-sourced Playwright MCP, and their Copilot strategy benefits from cross-platform access). Google is mixed but generally supportive of open standards. Apple, however, historically resists cross-platform standardization, controls iOS/macOS tightly, and has shown no interest in opening accessibility APIs beyond their existing public surface. Without robust Apple platform coverage, any standard is incomplete — and coverage may depend on reverse-engineering rather than cooperation.

The **"reading" problem is fundamentally harder than the "writing" problem.** AccessKit proves that a universal schema can *provide* trees to platform APIs. But *consuming* trees from arbitrary applications means dealing with inconsistent accessibility implementations, missing labels, broken hierarchies, and apps that bypass accessibility APIs entirely. Microsoft's UFO² team observed that agent "performance correlates directly with accessibility support quality" — and many applications, especially on macOS (only ~33% offer full accessibility support per the Screen2AX paper) and legacy Windows apps, expose incomplete or garbage trees.

The **lowest-common-denominator problem** is real but solvable. A flat intersection of all platforms would lose Windows UIA's control patterns, macOS's unique actions, and web ARIA's rich landmark system. However, LSP's capability negotiation pattern shows how to preserve platform-specific richness within a common framework — the core schema handles the 80% case, optional capabilities handle the rest.

**Performance matters for some use cases but not others.** Screen readers need millisecond-level response times. AI agents, which already spend seconds on LLM inference per step, can tolerate the overhead of an abstraction layer. The initial target audience should be AI agent developers, who have the highest pain tolerance for latency and the strongest demand for cross-platform coverage.

## Conclusion: infrastructure gap with a closing window

The research reveals a clear pattern: **ARIA provides the vocabulary, AccessKit proves the schema is viable, Playwright MCP demonstrates the demand for web, and the AI agent ecosystem is desperately reinventing the wheel on every platform.** The gap is a consumer-side library with a protocol-grade schema that reads arbitrary application trees across platforms and exposes them in a unified format.

The highest-impact approach combines both the protocol and library angles, following the LSP playbook. First, ship a Python library (`pip install uitree`) built on AccessKit's schema that wraps pywinauto, atomacos/pyobjc, pyatspi, Appium, and Playwright CDP behind a single API returning `{role, name, state, bounds, children}` trees. Target AI agent developers first — they're the fastest-growing segment, least locked into existing tools, and most tolerant of imperfect coverage. Then formalize the schema as an MCP-compatible protocol specification, enabling any language to implement adapters. Begin with Windows and Android (most open platforms), add macOS/Linux, and handle iOS with best-effort.

The window for establishing an open standard is roughly **12–24 months**. After that, major AI companies will have built proprietary solutions (as RPA vendors did), and the opportunity for an open protocol will narrow significantly. The building blocks exist. The demand is real. What's missing is someone assembling them into a standard before fragmentation becomes permanent.